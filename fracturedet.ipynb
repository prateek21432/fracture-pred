{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateek21432/fracture-pred/blob/main/fracturedet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naa1J7IxP9h9",
        "outputId": "6a48fb2b-6f88-4184-fbb5-835b5987238f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO7UjqM4P7J5",
        "outputId": "f0d879f7-db90-476e-e5c4-058dfaba1b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9246 images belonging to 2 classes.\n",
            "Found 839 images belonging to 2 classes.\n",
            "Found 506 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 531ms/step - accuracy: 0.5633 - loss: 0.6808 - val_accuracy: 0.6830 - val_loss: 0.6112\n",
            "Epoch 2/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 519ms/step - accuracy: 0.6506 - loss: 0.6207 - val_accuracy: 0.7294 - val_loss: 0.5623\n",
            "Epoch 3/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 569ms/step - accuracy: 0.7010 - loss: 0.5768 - val_accuracy: 0.7175 - val_loss: 0.5713\n",
            "Epoch 4/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 524ms/step - accuracy: 0.7125 - loss: 0.5540 - val_accuracy: 0.7747 - val_loss: 0.4785\n",
            "Epoch 5/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 522ms/step - accuracy: 0.7436 - loss: 0.5227 - val_accuracy: 0.6830 - val_loss: 0.6208\n",
            "Epoch 6/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 520ms/step - accuracy: 0.7570 - loss: 0.5047 - val_accuracy: 0.7914 - val_loss: 0.4647\n",
            "Epoch 7/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 530ms/step - accuracy: 0.7584 - loss: 0.4856 - val_accuracy: 0.8260 - val_loss: 0.3931\n",
            "Epoch 8/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 523ms/step - accuracy: 0.7751 - loss: 0.4665 - val_accuracy: 0.8176 - val_loss: 0.4070\n",
            "Epoch 9/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 522ms/step - accuracy: 0.8040 - loss: 0.4370 - val_accuracy: 0.7950 - val_loss: 0.4405\n",
            "Epoch 10/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 524ms/step - accuracy: 0.8051 - loss: 0.4260 - val_accuracy: 0.8486 - val_loss: 0.3776\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 335ms/step - accuracy: 0.7573 - loss: 0.5087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7708\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# Enable loading of truncated images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Path to dataset directories\n",
        "train_dir = \"/content/drive/MyDrive/Bone_Fracture_Binary_Classification/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Bone_Fracture_Binary_Classification/val\"\n",
        "test_dir = \"/content/drive/MyDrive/Bone_Fracture_Binary_Classification/test\"\n",
        "\n",
        "# Function to check and remove corrupted images\n",
        "def remove_corrupted_images(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # Check if the image is valid\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                print(f\"Removing corrupted image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Remove corrupted images from all datasets\n",
        "remove_corrupted_images(train_dir)\n",
        "remove_corrupted_images(val_dir)\n",
        "remove_corrupted_images(test_dir)\n",
        "\n",
        "# ImageDataGenerator for loading and augmenting images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Load images using generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Define CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train Model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Save Model\n",
        "model.save(\"/content/drive/MyDrive/Bone_Fracture_Binary_Classification/model/model.h5\")\n",
        "print(\"Model saved successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "\n",
        "# Allow PIL to load truncated images instead of throwing an error\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"/content/drive/MyDrive/Bone_Fracture_Binary_Classification/model/model.h5\")\n",
        "\n",
        "# Define the path to the test images\n",
        "test_dir = \"/content/drive/MyDrive/Bone_Fracture_Binary_Classification/testing\"\n",
        "\n",
        "# Define image size (same as used during training)\n",
        "image_size = (224, 224)\n",
        "\n",
        "# Get class labels (assuming binary classification: 'Fractured' and 'Normal')\n",
        "class_labels = [\"Fractured\", \"Normal\"]\n",
        "\n",
        "# Function to preprocess and predict an image\n",
        "def predict_image(image_path):\n",
        "    try:\n",
        "        # Load image\n",
        "        img = Image.open(image_path)\n",
        "        img = img.convert(\"RGB\")  # Ensure it's in RGB format\n",
        "        img = img.resize(image_size)  # Resize\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(img_array)[0][0]\n",
        "\n",
        "        # Convert prediction to class label\n",
        "        class_index = 1 if prediction >= 0.5 else 0\n",
        "        confidence = prediction if prediction >= 0.5 else 1 - prediction\n",
        "        return class_labels[class_index], confidence\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping corrupted image: {image_path} - Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Iterate over test images and classify them\n",
        "print(\"Testing Images...\\n\")\n",
        "for root, _, files in os.walk(test_dir):\n",
        "    for file in files:\n",
        "        image_path = os.path.join(root, file)\n",
        "        label, confidence = predict_image(image_path)\n",
        "        if label is not None:  # Skip corrupted images\n",
        "            print(f\"Image: {file} → Predicted: {label} (Confidence: {confidence:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu__xpis_WeT",
        "outputId": "f884a372-6c4b-4d3e-abda-fc2ba3c83222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Images...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}